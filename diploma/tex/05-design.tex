\chapter{Конструкторский раздел}

В данном разделе описывается разработанный метод и особенности разработанного метода; формулируются и описываются ключевые шаги метода в виде схем алгоритмов; описываются структуры данных, используемые в алгоритмах, и взаимодействие отдельных частей системы.

\section{Разработанный метод}

Разработанный метод основывается на методе, анализирующий гистограмму изображения окружения, которому не требуется вычислять положения ИС в каждом кадре, но в отличие от него учитывает глубину окружения \cite{osti2019real}.

Метод состоит из 5 основных этапов:

\begin{enumerate}
	\item[---] захват изображения;
	\item[---] обработка изображения;
	\item[---] поиск положения источников света;
	\item[---] построение геометрии окружения;
	\item[---] отрисовка теней.
\end{enumerate}

\subsection{Особенности метода}

В этом методе в качестве исходных данных используется информация о глобальном освещении окружающей среды и любых источниках света, присутствующих вокруг пользователя, из HDR-изображений. Исходные изображения должны обладать следующими свойствами:

\begin{itemize}
	\item[---] они должны быть всенаправленными, т.е. для каждого направления пространства имеется пиксель, представляющий это направление;
	\item[---] значения пикселей соответствуют количеству света, поступающего с этого направления.
\end{itemize}

Также стоит уточнить, что первые 3 этапа метода (захват изображения, обработка изображения, поиск положения источников света) обрабатываются в начале сессии или по необходимости, например, при смене освещения окружения, а остальные 2 (построение геометрии окружения, отрисовка теней) обрабатываются в каждом кадре.

\subsection{Захват изображения}

На основе исходных снимков создается т. н. карта сферы, которая представляет собой сферическое изображение на 360 градусов окружения, где будут размещены синтетические объекты. Чтобы удовлетворить свойству всенаправленности, наиболее часто используемым методом является фотографирование зеркальной сферы: этот метод позволяет получать свет, исходящий из-за сферы, поскольку лучи за сферой отклоняются и захватываются камерой спереди. Другими словами, можно использовать всеракурсную камеру. Другой метод состоит в том, чтобы сделать несколько фотографий всего окружения и скомпоновать их вместе, накладывая друг на друга, чтобы сформировать карту сферы \cite{osti2019real}.

Схема алгоритма изображена на рисунке \ref{img:CapturingImage.drawio}

\includeimage
{CapturingImage.drawio}
{f}
{H}
{0.465\textwidth}
{Схема алгоритма захвата изображения}

\subsection{Обработка изображения}

Полученную карту сферы конвертируется из цветного изображения в изображение в оттенках серого для более простого применения порогового значения к значениям цвета пикселей, поскольку в изображении в оттенках серого они варьируются только от 0 до 255. Стоит отметить, что не все цветные изображения после конвертировании в изображение в оттенках серого имеют пиксели, которые варьируются от 0 до 255. Например, слишком яркие или слишком тусклые изображения.

Далее проверяется следующее условие:

\begin{equation}
	\frac{\text{max}(\text{PixelValue})}{\text{average}(\text{PixelValue})} \geqslant 1.5,
\end{equation}

где PixelValue -- значение пикселя, max(PixelValue) -- максимальное значение пикселя, average(PixelValue) -- среднее значение пикселя.

Если это условие верно, то это означает, что разница между максимальным значением и средним значением пикселей достаточно, чтобы утверждать, что существует видимая разница между окружающим светом и возможным точечным светом. В ином случае возможно ошибочное отождествление окружающего света с точечным светом, что приводит, во-первых, к слишком высокой плотности белых пикселей и, во-вторых, к неточному расположению света на этапе поиска положения источников света \cite{osti2019real}.

Далее происходит анализ гистограммы изображения \cite{img_hists}. Вычисляется минимальный процент спектра (начиная с 0), который покрывает не менее 98\% пикселей, после чего оставшуюся часть спектра берут для обнаружения областей, где могут располагаться ИС. Этот шаг позволяет убрать ненужные области изображения посредством затемнения и рассматривать только те области изображения, которые соответствуют реальным ИС. Полученный результат обрабатывается медианным фильтром размытия в качестве метода шумоподавления, поскольку возможно наличие некоторых областей, которые соответствуют отражениям объектов в окружающей среде \cite{osti2019real}.

Схема алгоритма изображена на рисунке \ref{img:ProcessingImage.drawio}

\includeimage
{ProcessingImage.drawio}
{f}
{H}
{0.8\textwidth}
{Схема алгоритма обработки изображения}

\subsection{Поиск положения источников света}

У полученного изображения вычисляются контуры ИС. Из полученных контуров определяются моменты контуров, из которых можно получить центроиды каждого ИС. 

Моменты изображения представляют собой средневзвешенное значение интенсивности пикселей изображения, то есть это суммарная характеристика контура, рассчитанная интегрированием (суммированием) всех пикселей контура. Все что необходимо -- это вычислить сумму интенсивностей всех пикселей и получить на выходе значение \cite{sns_tras}.

Из координат центроида на изображении окружения $(x_{pixel}, y_{pixel})$ можно получить зенит $\theta$ и азимут $\phi$ ИС на сферической карте следующим образом. Координата $x_{pixel}$ пропорциональна зениту, а координата $y_{pixel}$ пропорциональна азимуту, из чего следуют соотношения \cite{osti2019real}:

\begin{equation}
	\begin{aligned}
		\begin{split}
			\frac{x_{\text{pixel}}}{\theta} &= \frac{\text{width}}{2\pi}, \\
			\frac{\text{height} - y_{\text{pixel}}}{\phi} &= \frac{\text{height}}{\pi}, 
		\end{split}
	\end{aligned}
\end{equation}

где width, height -- ширина и высота исходного изображения окружения соответственно. Стоит отметить, что координата $r$ у ИС равна глубине пикселя карты с координатами $(x_{pixel}, y_{pixel})$, т. е. 

\begin{equation}
	r = depth[x_{pixel}, y_{pixel}],
\end{equation}
 
где $depth$ -- двумерный массив, хранящий информацию о глубине каждого пикселя карты сферы.

Зная значения координат ИС в сферических координатах, можно их перевести в декартову систему координат:

\begin{equation}
	\begin{aligned}
		\begin{split}
			x &= r \sin\theta \cos\phi, &&\\
			y &= r \sin\theta \sin\phi, &&\\
			z &= r \cos\phi. &&\\
		\end{split}
	\end{aligned}
\end{equation}

Таким образом, становится известно положение ИС в трехмерном пространстве.

Схема алгоритма изображена на рисунке \ref{img:SearchingLightSources.drawio}

\includeimage
{SearchingLightSources.drawio}
{f}
{H}
{0.325\textwidth}
{Схема алгоритма поиска положения ИС}

\subsection{Построение геометрии окружения}

Алгоритм построение сетки, отражающей геометрию окружения, состоит из двух этапов \cite{du2020depthlab}: 

\begin{itemize}
	\item[---] строится плоская прямоугольная сетка, количество вершин которой по длине и ширине определяется размерами входной карты глубины;
	\item[---] каждая вершина, сопоставленная с точкой карты глубины, смещается на основе повторно спроецированного значения глубины.
\end{itemize}

Схема алгоритма изображена на рисунке \ref{img:MeshBuilding.drawio}

\includeimage
{MeshBuilding.drawio}
{f}
{H}
{0.625\textwidth}
{Схема алгоритма построения геометрии окружения в реальном времени}

Функция \textbf{any} проверяет булевое выражения для каждого элемента некоторого списка. Если хоть для одного элемента списка выражение истинно, то функция возвращает 1, иначе -- 0.

Перевод координат вершины в мировые координаты происходит по следующим уравнениям:

\begin{equation}
	\begin{split}
		v_p = D[p.x, p.y] \cdot K^{-1} [p, 1], \\
		g_p = C \cdot [v_p, 1],
	\end{split}
\end{equation}

где $D$ -- карта глубины, $p$ -- точка в экранном пространстве, соответствующая вершине, с координатами $x$ и $y$, $K$ -- матрица внутренних параметров камеры, $v_p$ -- вершина с координатами в пространстве камеры, $g_p$ -- вершина с координатами в мировом пространстве, $C = [R|t]$ -- матрица перевода в пространство камеры, состоящая из матрицы поворота $R$ размером $3 \times 3$ и вектора перемещения $t$ размером $3 \times 1$.

\subsection{Отрисовка теней}

Отрисовка теней происходит по алгоритмам машинной графики. Зная местоположение каждого ИС, расставляются их виртуальные аналоги. В итоге происходит синтез и отображение виртуальной сцены с виртуальным объектом, отбрасывающим тень от <<реальных>> ИС.

Схема алгоритма изображена на рисунке \ref{img:ShadowDrawing.drawio}

\includeimage
{ShadowDrawing.drawio}
{f}
{H}
{0.3\textwidth}
{Схема алгоритма отрисовки теней}

\section{Структуры данных}

В таблице \ref{DataStructures} приведены структуры данных, используемые в алгоритмах.

\begin{table}[H]
	\caption{Cтруктуры данных, используемые в алгоритмах}
	\label{DataStructures}
	\begin{center}
		\begin{tabular}{| p{4 cm} | p{11 cm} |} 
			\hline
			Данные & Представление \\
			\hline
			Точка трехмерного пространства & Координаты X, Y, Z \\
			\hline
			Вектор & Точка трехмерного пространства  \\
			\hline
			Мировая система координат (МСК) & Точка трехмерного пространства с тремя ортонормированными векторами \\
			\hline
			Локальная система координат (ЛСК) & Точка трехмерного пространства относительно МСК с тремя ортонормированными векторами \\
			\hline
			Вершина & Точка трехмерного пространства \\
			\hline
			Полигон & Массив из трех индексов списка вершин \\
			\hline
			Полигональная сетка & Список полигонов \\
			\hline
			Карта сферы & Растровое изображение \\
			\hline
			Карта глубины & Растровое черно-белое изображение \\
			\hline
			Камера & Пространство обзора (ЛСК); ширина и высота виртуального экрана; отступы от центра ЛСК по оси Z ближней и дальней плоскости \\
			\hline
			Источник света & Точка в трехмерном пространстве; параметры источника света \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\section{Взаимодействие отдельных частей системы}

На рисунке \ref{img:AppStructure.drawio} представлена схема взаимодействия отдельных частей системы.

\includeimage
{AppStructure.drawio}
{f}
{H}
{\textwidth}
{Схема взаимодействия отдельных частей системы}

\section*{Вывод}

В данном разделе был описан разработанный метод и особенности разработанного метода; были сформулированы и описаны ключевые шаги метода в виде схем алгоритмов. Также были описаны структуры данных, используемые в алгоритмах, и взаимодействие отдельных частей системы.