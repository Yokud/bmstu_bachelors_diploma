\chapter{Аналитическая часть}


\section{Обзор существующих методов наложения теней в ДР}

\subsection{Метод с использованием HDR изображений}

В этом методе в качестве исходных данных используется информация о глобальном освещении окружающей среды и любых источниках света, присутствующих вокруг пользователя, из HDR-изображений \cite{hdri, rtsm}. Исходные изображения должны обладать следующими свойствами:

\begin{itemize}
	\item они должны быть всенаправленными, т.е. для каждого направления пространства имеется пиксель, представляющий это направление;
	\item значения пикселей соответствуют количеству света, поступающего с этого направления.
\end{itemize}

Метод состоит из 4 основных этапов:

\begin{enumerate}
	\item захват изображения;
	\item обработка изображения;
	\item поиск положения источников света;
	\item отрисовка теней.
\end{enumerate}

\subsubsection*{Захват изображения}

На основе исходных снимков создается т. н. карта сферы, которая представляет собой сферическое изображение на 360 градусов окружения, где будут размещены синтетические объекты. Чтобы удовлетворить свойство всенаправленности, наиболее часто используемым методом является фотографирование зеркальной сферы: этот метод позволяет получать свет, исходящий из-за сферы, поскольку лучи за сферой отклоняются и захватываются камерой спереди. Более простой метод состоит в том, чтобы сделать несколько фотографий всего окружения и скомпоновать их вместе, накладывая друг на друга, чтобы сформировать карту сферы \cite{rtsm}.

\subsubsection*{Обработка изображения}

Полученную карту сферы конвертируют из RGB-изображения в черно-белое для более простого применения порогового значения к
значениям цвета пикселей, поскольку они варьируются только от 0 до 255. Стоит отметить, что не все RGB-изображения после конвертировании в черно-белый формат имеют пиксели, которые варьируются от 0 до 255, например, слишком яркие или слишком темные.

После преобразования изображения можно применить для него пороговое значение, чтобы удалить все пиксели со значением цвета ниже заданного порога. Этот порог выбирается путем анализа гистограммы изображения \cite{img_hists}.

Далее проверяется следующее условие:

\begin{equation}
	\frac{Max(PixelValue)}{Average(PixelValue)} \geq 1.5
\end{equation}

Если это условие верно, то это означает, что разница между максимальным значением и средним значением пикселей достаточно, чтобы утверждать, что существует видимая разница между окружающим светом и возможным точечным светом. В ином случае возможно ошибочное отождествление окружающего света с точечным светом, что приводит, во-первых, к слишком высокой плотности белых пикселей и, во-вторых, к неточному расположению света на этапе поиска положения источников света \cite{rtsm}.

Далее происходит оценка порогового значения. Если 93\% спектра (начиная с 0) покрывают не менее 98\% пикселей, то можно пороговать оставшиеся 7\%. Этот шаг позволяет обрезать изображение и рассматривать только те области изображения, которые соответствуют реальным источникам света. Полученный результат обрабатывается медианным фильтром размытия в качестве метода шумоподавления, поскольку возможно наличие некоторых областей со значением пикселей выше порогового значения из-за отражений объектов в окружающей среде \cite{rtsm}.

\subsubsection*{Поиск положения источников света}

У полученного изображения вычисляются контуры источников света. Из полученных контуров определяются его моменты, из которых можно получить центроиды каждого источника света.

Из координат центроида $(x, y)$ можно получить координату $z$ следующим образом. Координата $x$ пропорциональна повороту вокруг оси $Y$, а координата $y$ пропорциональна повороту вокруг оси $X$, из чего следуют соотношения \cite{rtsm}:

\begin{equation}
	\begin{split}
		\frac{x}{\theta} = \frac{width}{2\pi} \\
		\frac{y}{\phi} = \frac{height}{\pi},
	\end{split}
\end{equation}

где $\theta, \phi$ -- углы поворота вокруг осей $Y$ и $X$ соответственно, $width, height$ -- ширина и высота исходного изображения окружения. Зная углы поворота вокруг осей, можно вычислить модуль координаты $z$ следующим образом:

\begin{equation}
	\begin{split}
		z_{xz} = x\cos(\theta) \\
		z_{yz} = y\cos(\phi), \\
		|z| = \sqrt{z_{xz} ^ 2 + z_{yz} ^ 2} \\
	\end{split}
\end{equation}

где $z_{xz}$ -- координата $z$ проекции точки положения виртуального ИС на плоскость $XZ$, $z_{yz}$ -- координата $z$ проекции точки положения виртуального ИС на плоскость $YZ$. Знак координаты $z$ можно восстановить следующим образом:

\begin{equation}
	\begin{split}
		\left[
		\begin{gathered}
			z = -|z|, z_{xz} < 0 \vee z_{yz} < 0 \vee z_{xz} < 0 \wedge z_{yz} < 0 \\
			z = |z|, z_{xz} \geq 0 \vee z_{yz} \geq 0
		\end{gathered}
		\right.
	\end{split}
\end{equation}

Таким образом, становится известно положение ИС в трехмерном пространстве.

\subsubsection*{Отрисовка теней}

Этот этап ничем особым не отличается по сравнению с остальными: отрисовка теней происходит по тем же алгоритмам, что и в машинной графике. Зная местоположение каждого ИС, расставляются их виртуальные аналоги. В итоге происходит синтез и отображение виртуальной сцены с виртуальным объектом, отбрасывающий тень от <<реальных>> ИС.

\subsubsection*{Преимущества и недостатки}

Преимуществом такого метода является быстродействие: для наложения тени на виртуальный объект требуется только вычислить тень, падающую от него, т. к. все шаги с рассчетом положения ИС уже были проделаны.

Недостатками такого метода являются:
\begin{itemize}
	\item требуется предварительная подготовка информация об окружении, т. е. динамическая смена окружения не предусмотрена;
	\item корректная отрисовка теней происходит только на плоской поверхности, т. е. нельзя воспроизвести её искажение, т. к. нет информации о поверхности проецирования.
\end{itemize}

\subsection{Метод на основе анализа теней ИС}

Метод основан на анализе HDR-изображений, восстанавливая параметры освещения в сложных сценах с несколькими ИС. В качестве исходных данных метод использует HDR-изображение видимого пространства и карту глубины сцены.

На основе полученных данных строится трехмерная сетка окружения, после чего происходит поиск теней и распознавание объектов, которые их отбрасывают. Потом добавляются горизонтальные поверхностные детекторы света. Их количество зависит от высоты помещения, шаг между соседними детекторами составляет 0.1–0.2 м (в среднем 5-10\% от высоты помещения) \cite{hdr_method}.

Далее происходит добавление виртуальных узких конических ИС по контурам теней для каждого объекта, имеющего тень. Их количество зависит от сложности контура тени. После этого определяется ориентация ранее добавленных виртуальных ИС,  расположенных по контуру тени, на контур предмета.

На следующем шаге анализируется относительная площадь пересечения большинства теней по отношению к суммарной площади теней. Иными словами, происходит следующее:

\begin{itemize}
	\item вычисляется площадь пересечения тени от виртуального ИС и тени с реального ИС в горизонтальной плоскости;
	\item площадь пересечения теней д. б. минимальной, если это не так, то она минимизируется, изменяя координаты виртуального ИС в горизонтальной плоскости;
	\item повторить предыдущие действия для всех виртуальных ИС.
\end{itemize}

По координатам точки в горизонтальной плоскости и положению этой плоскости можно восстановить координаты реального источника света и расположить виртуальные ИС по вычисленным координатам \cite{hdr_method}.

Последним шагом является синтез и отображение виртуальной сцены с виртуальным объектом, отбрасывающий тень от <<реальных>> ИС посредством алгоритмов машинной графики.

Схема метода представлена на рисунке \ref{img:HDR_Method}.

\includeimage
	{HDR_Method}
	{f}
	{H}
	{0.25\textwidth}
	{Схема метода наложения теней в ДР с использованием HDR изображений и карты глубины}

\subsection{Метод с использованием RGBD-данных}

\subsection{Метод с использованием сверточных нейронных сетей}

\subsection{Метод с использованием сверточных нейронных сетей и трассировки теневых лучей}

Суть метода -- определить координаты ИС по теням, отбрасываемые объектами. Он основан на предположении, что  для небольших источников света тень объекта является изображением центральной проекции этого объекта на поверхность <<пола>>. Следовательно, зная сопряженные координаты точек границ теней и координаты точек границ объектов, отбрасывающих эти тени, можно восстановить центральную проекцию и найти положение источника света \cite{sns_tras}.

Однако найти точки сопряжения -- задача нетривиальная, особенно для сложных сцен, когда есть много теней от разных ИС и когда тени не проецируются на плоскую поверхность. Метод основан на формировании пучков лучей, исходящих из точек на границе тени. В этом случае предполагается, что среди пучков лучей, испускаемых из тени к объекту, будет хотя бы один, идущий в направлении источника света. Эти лучи формируются из точек, полученных после определения контуров объектов и теней. В качестве контура объекта рассматривается не только его геометрический контур, но и световой контур, т. е. граница света и тени на самом освещаемом объекте. Группа лучей, исходящих из разных точек тени на разные точки объекта, может сформировать каустику, которая будет находиться вблизи источника света. Центр перетяжки этой каустики в пространстве сцены соответствует положению источника света. Поэтому основная задача метода -- найти группу лучей, формирующих каустику \cite{sns_tras}.

В качестве исходных данных используется изображение в формате RGBD, не требующее калибровки по реальным значениям яркости.

Данный метод состоит из двух этапов.
\begin{enumerate}
	\item Обучение сверточной нейронной сети для определения границ объектов и теневых областей RGBD-изображений, полученных устройством ДР.
	\item Использование алгоритмов машинного зрения для определения положения источников освещения в сцене.
\end{enumerate}

Более подробно метод выглядит так.

\begin{enumerate}
	\item Получение входных данных от MR-устройства, а именно изображения в RGBD формате, содержащего карты глубины сцены.
	\item Формирование облака точек из RGBD изображения. Для
	формирования используется информация о состоянии и ориентации устройства ДР.
	\item Анализ изображения. Использование обученной сверточной нейронной сети для определения всех теневых областей на изображении.
	\item Идентификация объектов, отбрасывающих тени, и выделение их разными цветами на изображении. Нахождение границ объектов, включая световые границы в области освещаемой и теневой части объекта.
	\item Формирование и сохранение координат точек видимых и световых границ объектов и теней. 
	\item Формирование облака точек вероятного пересечения лучей, исходящих из разных точек тени и объекта. Образуются пары несопряженных лучей, т. е. лучи должны исходить из разных точек через разные точки одного объекта. Поскольку фактическое пересечение таких лучей невозможно, выполняется поиск точки на отрезке с минимальным расстоянием, соединяющим две эти прямые. Точки позади объекта или за пределами области определения сцены отбрасываются. 
	\item Точки, полученные в результате пересечения траекторий лучей, помечаются номером объекта, через который прошел луч. Эта маркировка позволяет сортировать сформированные лучи.
	\item В области сцены формируется пространственная структура для определения плотности точек пересечения лучей. Структура имеет многоуровневую организацию, где каждый уровень представляет собой обычную трехмерную регулярную решетку, расположенную в родительской ячейке.
	\item Анализ областей концентрации точек, которые принимаются за положение источников света. Для каждой области координаты источника света усредняются, и средняя точка берется за точку положения источника света.
	\item Для найденных точек проверяется правильность нахождения координат источника света. Для этого от источника света на границе тени испускаются лучи и оценивается отклонение координат соответствующих точек от ближайших точек границ объекта. Если отклонение находится в пределах допуска, то найденная точка принимается за центральную точку источника света, в противном случае источник света считается ложным и отклоняется. Кроме того, близкорасположенные источники света, найденные для различных объектов, объединяются в один источник света.
\end{enumerate}

\subsubsection*{Определение контуров теней и объектов}

Изображения в оттенках серого и цветные изображения могут содержать значительный шум, заключающийся в случайных вариациях яркости или цветов точек изображения. Поэтому для определения контуров объектов и теней необходимо сперва устранить шум изображения, для чего используются различные методы фильтрации и алгоритмы компьютерного зрения. Для этого используются алгоритмы Кэнни \cite{canedgedetect} для обнаружения границ изображения, затем размытие по Гауссу \cite{gaus_smooth} и операция наращивания \cite{dilation} для устранения шума на границах изображения. Чтобы оставить только контуры границ, используется алгоритм скелетизации \cite{skeleton}, который уменьшает бинарные объекты до ширины одной точки изображения. 

После определения всех контуров объектов и теней на изображении необходимо найти соответствие между ними. В первую очередь строятся регионы интересов \cite{roi} области контуров, и если они соприкасаются, т. е. имеют общие границы, то с большой вероятностью контур тени соответствует контуру объекта \cite{sns_tras}.

Кроме того, используется еще один метод сопоставления контуров, заключающийся в использовании функции, вычисляющей и сравнивающей по заданным регионам интересов «моменты» контуров изображений объектов и теней сцены. Моменты изображения представляют собой средневзвешенное значение интенсивности пикселей изображения, т. е. это суммарная характеристика контура, рассчитанная интегрированием (суммированием) всех пикселей контура. Все что необходимо -- это вычислить сумму интенсивностей всех пикселей и получить на выходе значение. Далее в функцию сравнения контуров подаются полученные значения и возвращается метрика, показывающая сходство. Чем ниже результат на выходе функции (чем ближе она к нулю), тем больше соответствие и тем вероятнее, что сравниваемые контуры тени и объекта имеют одно происхождение, т. е. тень была сформирована данным объектом.

\subsubsection*{Формирование лучей}

После того, как были определены все необходимые координаты на исходном изображении контуров объектов и их теней, начинается процесс формирования лучей. Они формируются с заданным шагом по контуру, например, исходя из соображения, что на контуре изображения и тени не должно быть больше 10 или 20 точек \cite{sns_tras}. Исходя из этого на контурах выбираются точки с соответствующим шагом, через которые затем выпускаются лучи, и вычисляются точки, находящиеся на минимальном расстоянии между этими лучами, т. е. точки перетяжки лучей. Вычисление точек перетяжки основывается на методе наименьших квадратов, что является стандартным подходом в регрессионном анализе для аппроксимации решения переопределенных систем путем минимизации суммы квадратов, полученных в результатах каждого отдельного уравнения \cite{mnk}.

Далее определяется максимальная плотность точек перетяжки. По найденным точкам в области наибольшей плотности вычисляются моменты и находится средняя точка.

Необходимо отметить, что если в процессе поиска координат источников света использовались два или более объектов сцены, то найденные облака точек, имеющие максимальную плотность и характеризующие источники света от разных групп объектов – теней, можно объединять в один общий источник света, имеющий конечный размер. Это объединение можно делать только в том случае, если облака точек были порождены различными объектами, поскольку один объект, формирующий разные тени, не может создать один источник \cite{sns_tras}.

\section{Анализ предметной области}



\section{Критерии сравнения}



\section{Классификация существующих методов}


