\chapter{Аналитическая часть}


\section{Обзор существующих методов наложения теней в AR}

\subsection{Метод с использованием HDR изображений}

В этом методе в качестве исходных данных используется информация о глобальном освещении окружающей среды и любых источниках света, присутствующих вокруг пользователя, из HDR-изображений \cite{hdri, rtsm}. Исходные изображения должны обладать следующими свойствами:

\begin{itemize}
	\item они должны быть всенаправленными, т.е. для каждого направления пространства имеется пиксель, представляющий это направление;
	\item значения пикселей соответствуют количеству света, поступающего с этого направления.
\end{itemize}

Метод состоит из 4 основных этапов:

\begin{enumerate}
	\item захват изображения;
	\item обработка изображения;
	\item поиск положения источников света;
	\item отрисовка теней.
\end{enumerate}

\subsubsection*{Захват изображения}

На основе исходных снимков создается т. н. карта сферы, которая представляет собой сферическое изображение на 360 градусов окружения, где будут размещены синтетические объекты. Чтобы удовлетворить свойство всенаправленности, наиболее часто используемым методом является фотографирование зеркальной сферы: этот метод позволяет получать свет, исходящий из-за сферы, поскольку лучи за сферой отклоняются и захватываются камерой спереди. Более простой метод состоит в том, чтобы сделать несколько фотографий всего окружения и скомпоновать их вместе, накладывая друг на друга, чтобы сформировать карту сферы \cite{rtsm}.

\subsubsection*{Обработка изображения}

Полученную карту сферы конвертируют из RGB-изображения в черно-белое для более простого применения порогового значения к
значениям цвета пикселей, поскольку они варьируются только от 0 до 255. Стоит отметить, что не все RGB-изображения после конвертировании в черно-белый формат имеют пиксели, которые варьируются от 0 до 255, например, слишком яркие или слишком темные.

После преобразования изображения можно применить для него пороговое значение, чтобы удалить все пиксели со значением цвета ниже заданного порога. Этот порог выбирается путем анализа гистограммы изображения \cite{img_hists}.

Далее проверяется следующее условие:

\begin{equation}
	\frac{Max(PixelValue)}{Average(PixelValue)} \geq 1.5
\end{equation}

Если это условие верно, то это означает, что разница между максимальным значением и средним значением пикселей достаточно, чтобы утверждать, что существует видимая разница между окружающим светом и возможным точечным светом. В ином случае возможно ошибочное отождествление окружающего света с точечным светом, что приводит, во-первых, к слишком высокой плотности белых пикселей и, во-вторых, к неточному расположению света на этапе поиска положения источников света \cite{rtsm}.

Далее происходит оценка порогового значения. Если 93\% спектра (начиная с 0) покрывают не менее 98\% пикселей, то можно пороговать оставшиеся 7\%. Этот шаг позволяет обрезать изображение и рассматривать только те области изображения, которые соответствуют реальным источникам света. Полученный результат обрабатывается медианным фильтром размытия в качестве метода шумоподавления, поскольку возможно наличие некоторых областей со значением пикселей выше порогового значения из-за отражений объектов в окружающей среде \cite{rtsm}.

\subsubsection*{Поиск положения источников света}

У полученного изображения вычисляются контуры источников света. Из полученных контуров определяются его моменты, из которых можно получить центроиды каждого источника света.

Из координат центроида $(x, y)$ можно получить координату $z$ следующим образом. Координата $x$ пропорциональна повороту вокруг оси $Y$, а координата $y$ пропорциональна повороту вокруг оси $X$, из чего следуют соотношения \cite{rtsm}:

\begin{equation}
	\begin{split}
		\frac{x}{\theta} = \frac{width}{2\pi} \\
		\frac{y}{\phi} = \frac{height}{\pi},
	\end{split}
\end{equation}

где $\theta, \phi$ -- углы поворота вокруг осей $Y$ и $X$ соответственно, $width, height$ -- ширина и высота исходного изображения окружения. Зная углы поворота вокруг осей, можно вычислить модуль координаты $z$ следующим образом:

\begin{equation}
	\begin{split}
		z_{xz} = x\cos(\theta) \\
		z_{yz} = y\cos(\phi), \\
		|z| = \sqrt{z_{xz} ^ 2 + z_{yz} ^ 2} \\
	\end{split}
\end{equation}

где $z_{xz}$ -- координата $z$ проекции точки положения виртуального ИС на плоскость $XZ$, $z_{yz}$ -- координата $z$ проекции точки положения виртуального ИС на плоскость $YZ$. Знак координаты $z$ можно восстановить следующим образом:

\begin{equation}
	\begin{split}
		\left[
		\begin{gathered}
			z = -|z|, z_{xz} < 0 \vee z_{yz} < 0 \vee z_{xz} < 0 \wedge z_{yz} < 0 \\
			z = |z|, z_{xz} \geq 0 \vee z_{yz} \geq 0
		\end{gathered}
		\right.
	\end{split}
\end{equation}

Таким образом, становится известно положение ИС в трехмерном пространстве.

\subsubsection*{Отрисовка теней}

Этот этап ничем особым не отличается по сравнению с остальными: отрисовка теней происходит по тем же алгоритмам, что и в машинной графике. Зная местоположение каждого ИС, расставляются их виртуальные аналоги. В итоге происходит синтез и отображение виртуальной сцены с виртуальным объектом, отбрасывающий тень от <<реальных>> ИС.

\subsection*{Преимущества и недостатки}

Преимуществом такого метода является быстродействие: для наложения тени на виртуальный объект требуется только вычислить тень, падающую от него, т. к. все шаги с рассчетом положения ИС уже были проделаны.

Недостатками такого метода являются:
\begin{itemize}
	\item требуется предварительная подготовка информация об окружении, т. е. динамическая смена окружения не предусмотрена;
	\item корректная отрисовка теней происходит только на плоской поверхности, т. е. нельзя воспроизвести её искажение, т. к. нет информации о поверхности проецирования.
\end{itemize}

\subsection{Метод на основе анализа теней ИС}

Метод основан на анализе HDR-изображений, восстанавливая параметры освещения в сложных сценах с несколькими ИС. В качестве исходных данных метод использует HDR-изображение видимого пространства и карту глубины сцены.

На основе полученных данных строится трехмерная сетка окружения, после чего происходит поиск теней и распознавание объектов, которые их отбрасывают. Потом добавляются горизонтальные поверхностные детекторы света. Их количество зависит от высоты помещения, шаг между соседними детекторами составляет 0.1–0.2 м (в среднем 5-10\% от высоты помещения) \cite{hdr_method}.

Далее происходит добавление виртуальных узких конических ИС по контурам теней для каждого объекта, имеющего тень. Их количество зависит от сложности контура тени. После этого определяется ориентация ранее добавленных виртуальных ИС,  расположенных по контуру тени, на контур предмета.

На следующем шаге анализируется относительная площадь пересечения большинства теней по отношению к суммарной площади теней. Иными словами, происходит следующее:

\begin{itemize}
	\item вычисляется площадь пересечения тени от виртуального ИС и тени с реального ИС в горизонтальной плоскости;
	\item площадь пересечения теней д. б. минимальной, если это не так, то она минимизируется, изменяя координаты виртуального ИС в горизонтальной плоскости;
	\item повторить предыдущие действия для всех виртуальных ИС.
\end{itemize}

По координатам точки в горизонтальной плоскости и положению этой плоскости можно восстановить координаты реального источника света и расположить виртуальные ИС по вычисленным координатам \cite{hdr_method}.

Последним шагом является синтез и отображение виртуальной сцены с виртуальным объектом, отбрасывающий тень от <<реальных>> ИС посредством алгоритмов машинной графики.

Схема метода представлена на рисунке \ref{img:HDR_Method}.

\includeimage
	{HDR_Method}
	{f}
	{H}
	{0.25\textwidth}
	{Схема метода наложения теней в AR с использованием HDR изображений и карты глубины}

\subsection{Метод с использованием RGBD-камеры}

\subsection{Метод с использованием сверточных нейронных сетей}

\subsection{Метод с использованием сверточных нейронных сетей и трассировки теневых лучей}

\section{Анализ предметной области}



\section{Критерии сравнения}



\section{Классификация существующих методов}


